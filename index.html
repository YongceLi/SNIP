<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<script src="bootstrap.js"></script>
<script type="text/javascript" charset="utf-8" src="https://ajax.googleapis.com/ajax/libs/jquery/1.3.2/jquery.min.js"></script> 
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<style type="text/css">
    details > summary {
        display: inline-block;
        border: 2px solid #5C5962;
        border-radius: 5px;
        padding: 5px 10px;
        cursor: pointer;
        color: #0066CD;
        outline: none;
        font-size: 16px;
        background-color: white;
        list-style: none;
    }

    details > summary::-webkit-details-marker {
        display: none;
    }

    /* To remove the additional padding and margin */
    details {
        padding: 0;
        border: none;
    }

    details[open] > summary {
        border-bottom-left-radius: 0;
        border-bottom-right-radius: 0;
    }

    /* Optional: Add some padding and a border to the content for when the details are open */
    details > div {
        border: none;
        border-top: none;
        border-bottom-left-radius: 5px;
        border-bottom-right-radius: 5px;
        padding: 10px;
    }
body {
    font-family: "Titillium Web", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight: 300;
    font-size: 17px;
    margin-left: auto;
    margin-right: auto;
}

@media screen and (min-width: 980px){
    body {
        width: 980px;
    }
}

h1 {
    font-weight:300;
    line-height: 1.15em;
}

h2 {
    font-size: 1.75em;
}
a:link,a:visited {
    color: #5364cc;
    text-decoration: none;
}
a:hover {
    color: #208799;
}
h1 {
    text-align: center;
}
h2,h3 {
    text-align: left;
}

h1 {
    font-size: 40px;
    font-weight: 500;
}
h2 {
    font-weight: 400;
    margin: 16px 0px 4px 0px;
}
h3 {
    font-weight: 600;
    margin: 16px 0px 4px 0px;
}

.paper-title {
    padding: 1px 0px 1px 0px;
}
section {
    margin: 32px 0px 32px 0px;
    text-align: justify;
    clear: both;
}
.col-5 {
     width: 20%;
     float: left;
}
.col-4 {
     width: 25%;
     float: left;
}
.col-3 {
     width: 33%;
     float: left;
}
.col-2 {
     width: 50%;
     float: left;
}
.col-1 {
     width: 100%;
     float: left;
}

.author-row, .affil-row {
    font-size: 26px;
}

.author-row-new { 
    text-align: center; 
}

.author-row-new a {
    display: inline-block;
    font-size: 20px;
    padding: 4px;
}

.author-row-new sup {
    color: #313436;
    font-size: 12px;
}

.affiliations-new {
    font-size: 18px;
    text-align: center;
    width: 80%;
    margin: 0 auto;
    margin-bottom: 20px;
}

.row {
    margin: 16px 0px 16px 0px;
}
.authors {
    font-size: 26px;
}
.affiliatons {
    font-size: 18px;
}
.affil-row {
    margin-top: 18px;
}
.teaser {
    max-width: 100%;
}
.text-center {
    text-align: center;  
}
.screenshot {
    width: 256px;
    border: 1px solid #ddd;
}
.screenshot-el {
    margin-bottom: 16px;
}
hr {
    height: 1px;
    border: 0; 
    border-top: 1px solid #ddd;
    margin: 0;
}
.material-icons {
    vertical-align: -6px;
}
p {
    line-height: 1.25em;
}
.caption {
    font-size: 16px;
    color: #666;
    margin-top: 4px;
    margin-bottom: 10px;
}


video {
    display: block;
    margin: auto;
}


figure {
    display: block;
    margin: auto;
    margin-top: 10px;
    margin-bottom: 10px;
}
#bibtex pre {
    font-size: 14px;
    background-color: #eee;
    padding: 16px;
}
.blue {
    color: #2c82c9;
    font-weight: bold;
}
.orange {
    color: #d35400;
    font-weight: bold;
}
.flex-row {
    display: flex;
    flex-flow: row wrap;
    padding: 0;
    margin: 0;
    list-style: none;
}

.paper-btn-coming-soon {
    position: relative; 
    top: 0;
    left: 0;
}

.coming-soon {
    position: absolute;
    top: -15px;
    right: -15px;
}

.paper-btn {
  position: relative;
  text-align: center;

  display: inline-block;
  margin: 8px;
  padding: 8px 8px;

  border-width: 0;
  outline: none;
  border-radius: 2px;
  
  background-color: #5364cc;
  color: white !important;
  font-size: 20px;
  width: 100px;
  font-weight: 600;
}
.paper-btn-parent {
    display: flex;
    justify-content: center;
    margin: 16px 0px;
}

.paper-btn:hover {
    opacity: 0.85;
}

.example-btn {
  position: relative;
  text-align: center;

  display: inline-block;
  margin: 8px;
  padding: 8px 8px;

  border-width: 0;
  outline: none;
  border-radius: 2px;
  
  background-color: #4cd468;
  color: white !important;
  font-size: 20px;
  width: 220px;
  font-weight: 600;
}
.example-btn-parent {
    display: flex;
    justify-content: center;
    margin: 16px 0px;
}

.example-btn:hover {
    opacity: 0.85;
}

.container {
    margin-left: auto;
    margin-right: auto;
    padding-left: 16px;
    padding-right: 16px;
}

.venue {
    font-size: 23px;
}

.topnav {
    background-color: #EEEEEE;
    overflow: hidden;
}

.topnav div {
    max-width: 1070px;
    margin: 0 auto;
}

.topnav a {
    display: inline-block;
    color: black;
    text-align: center;
    vertical-align: middle;
    padding: 16px 16px;
    text-decoration: none;
    font-size: 18px;
}

.topnav img {
    padding: 2px 0px;
    width: 100%;
    margin: 0.2em 0px 0.3em 0px;
    vertical-align: middle;
}

pre {
    font-size: 0.9em;
    padding-left: 7px;
    padding-right: 7px;
    padding-top: 3px;
    padding-bottom: 3px;
    border-radius: 3px;
    background-color: rgb(235, 235, 235);
    overflow-x: auto;
}

.download-thumb {
    display: flex;
}

@media only screen and (max-width: 620px) {
    .download-thumb {
        display: none;
    }
}

.paper-stuff {
    width: 50%;
    font-size: 20px;
}

@media only screen and (max-width: 620px) {
    .paper-stuff {
        width: 100%;
    }
}
* {
  box-sizing: border-box;
}

.column {
  text-align: center;
  float: left;
  width: 16.666%;
  padding: 5px;
}
.column3 {
  text-align: center;
  float: left;
  width: 33.333%;
  padding: 5px;
}
.column4 {
  text-align: center;
  float: left;
  width: 50%;
  padding: 5px;
}
.column5 {
  text-align: center;
  float: left;
  width: 20%;
  padding: 5px;
}
.border-right {
    border-right: 1px solid black;
}
.border-bottom{
    border-bottom: 1px solid black;
}



/* Clearfix (clear floats) */
.row::after {
  content: "";
  clear: both;
  display: table;
}
.img-fluid {
  max-width: 100%;
  height: auto;
}
.figure-img {
  margin-bottom: 0.5rem;
  line-height: 1;
}








.rounded-circle {
  border-radius: 50% !important;
}






/* Responsive layout - makes the three columns stack on top of each other instead of next to each other */
@media screen and (max-width: 500px) {
  .column {
    width: 100%;
  }
}
@media screen and (max-width: 500px) {
  .column3 {
    width: 100%;
  }
}

</style>
<link rel="stylesheet" href="bootstrap-grid.css">

<script type="text/javascript" src="../js/hidebib.js"></script>
    <link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
    <head>
        <title>SNIP: Machine Unlearning via Selective Neuron-wise Interpretable Pruning</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta property="og:description" content="SNIP: Machine Unlearning via Selective Neuron-wise Interpretable Pruning"/>
        <link href="https://fonts.googleapis.com/css2?family=Material+Icons" rel="stylesheet">
    </head>

 <body>


<div class="container">
    <div class="paper-title">
    <h1> 
        SNIP: Machine Unlearning via Selective Neuron-wise Interpretable Pruning
    </div>

    <div id="authors">
        <center>
            <div class="author-row-new">
                Yongce Li,
                Mentor: Tsui-Wei (Lily) Weng
            </div>
        </center>
        <center>
        <div class="affiliations">
            <span> {yol013, lweng} @ucsd.edu </span>
        </div>

        <div class="affil-row">
            <div class="venue text-center"><b>HDSI Capstone 2024</b></div>
        </div>

        </center>

        <div style="clear: both">
            <div class="paper-btn-parent">
            <a class="paper-btn" href="TBA">
                <span class="material-icons"> description </span> 
                 Paper
            </a>
            <div class="paper-btn-coming-soon">
                <a class="paper-btn" href="TBA">
                    <span class="material-icons"> code </span>
                    Code
                </a>
            </div>
        </div></div>
        <!--
        <div style="clear: both">
            <div class="example-btn-parent">
            <a class="example-btn" href="./examples.html">
                <span class="material-icons"> dashboard </span> 
                 Neuron Examples
            </a>
        </div></div>
        -->
    </div>
    

    
    <section id="abstract"/>
        <hr>
        <h2>Abstract</h2>
        <div class="flex-row">
            <p>
                Large Language models (LLMs) have revolutionized the field of natural language processing with their remarkable performance across various applications. However, they suffer from issues related to untruthfulness and toxicity. With evolving data regulations, machine unlearning (MU) is becoming increasingly important to remove undesired outputs of LLMs, such as harmful, manipulated, or outdated information. This paper introduces a machine unlearning method specifically designed for LLMs. We present <b>S</b>elective <b>N</b>euron-wise <b>I</b>nterpretable <b>P</b>runing (<b>SNIP</b>), a machine unlearning method for LLMs, which is retrain-free and interpretable. SNIP selectively remove feed-forward layer neurons based on the relative importance of their neuron explanations on a targeted downstream task. To the best of our knowledge, SNIP is the first <em>interpretable</em> MU approach based on neuron concepts, which helps us understand and remove what have been learned in LLMs.
            </p>
            <div style="text-align: center; margin: auto;">
                <left><p><b>Figure 1:</b> Example of unlearning toxicity.</p></left>
                <center><img class="card-img-top" src="https://github.com/YongceLi/SNIP/blob/main/example_MU.png?raw=true" style="width:400px"></center>
            </div>
        </div>
    </section>

    <section id="motivation"/>
        <hr>
        <h2>Motivation</h2>
        <div class="flex-row">
            <p>
                <b>Interpretability:</b> <a href="https://openai.com/research/language-models-can-explain-neurons-in-language-models">OpenAI’s recent work [1]</a> showed that highly activated MLP neurons in LLMs are correlated with specific concepts, and we can use more capable LLMs (like GPT-4) to extract neuron concepts.<br><br>

                <b>Causal Relationship:</b> <a href="https://gandissect.csail.mit.edu/">Past work [2]</a> showed that by activating and deactivating sets of neurons in a GAN, we can control what objects to appear/disappear in the generated images.<br><br>

                <b>Question:</b> Are MLP neurons in LLMs also causally related with their detected concepts in model’s output? If so, can we control the model’s behavior by controlling the activation value of certain groups of neurons?  

            </p>
        </div>
    </section>

    <section id="method"/>
        <hr>
        <h2>Method</h2>
            <p>In this section, we describe SNIP step by step. In short, SNIP can be decomposed into 4 steps: 
            <ol>
                <li>For a subject model, using approach described in <a href="https://openai.com/research/language-models-can-explain-neurons-in-language-models">[1]</a> to get a concept set for all the MLP neurons, denote as C = {c<sub>ij</sub>}</li>
                <li>Given a forgetting dataset D, prompt GPT-4 to get important concept sets for D, denote as C'</li>
                <li>For each neuron n<sub>ij</sub> (neuron at i<sup>th</sup> MLP layer, j<sup>th</sup> index), calculate importance score s<sub>ij</sub> based on the similarity value between c<sub>ij</sub> and C'</li>
                <li>Rank all the MLP neurons based on their importance score, prune the top k neurons (k is a hyperparameter to be determined).</li>
            </ol>
            </p>
        <h3>
        Step 1: Interpret MLP neurons
        </h3>
        <p>In this step, our goal is to get neuron concept for all the MLP neurons in the subject model. We strictly follow the procedure introduced by OpenAI, using GPT-4 to summarize highly activated tokens of a neuron. Figure 2 shows the whole explanation pipeline. We first probe the subject model with a probing dataset. For each neuron, each token has an unique activation value, while some tokens are highly activated (marked as green). We prompt GPT-4 to summarize those tokens thus describe the functionality of that neuron. </p>
        <details> <summary>GPT-4 prompt</summary> 
        <br> <div style="white-space: pre-wrap;">
We're studying neurons in a neural network. Each neuron looks for some particular thing in a short document. Look at the parts of the document the neuron activates for and summarize in a single sentence what the neuron is looking for. Don't list examples of words.

The activation format is token&lt;tab&gt;activation. Activation values range from 0 to 10. A neuron finding what it's looking for is represented by a non-zero activation value. The higher the activation value, the stronger the match.

Neuron 1
Activations:
&lt;start&gt;
the		0
 sense		0
 of		0
 together	3
ness		7
 in		0
 our		0
 town		1
 is		0
 strong		0
.		0
&lt;end&gt;
&lt;start&gt;
[prompt truncated …]
&lt;end&gt;

Same activations, but with all zeros filtered out:
&lt;start&gt;
 together	3
ness		7
town		1
&lt;end&gt;
&lt;start&gt;
[prompt truncated …]
&lt;end&gt;

Explanation of neuron 1 behavior: the main thing this neuron does is find phrases related to community

[prompt truncated …]

Neuron 4
Activations:
&lt;start&gt;
Esc		0
aping		9
 the		4
 studio		0
,		0
 Pic		0
col		0
i		0
 is		0
 warmly	0
 affecting	3
&lt;end&gt;
&lt;start&gt;
[prompt truncated …]
&lt;end&gt;

Same activations, but with all zeros filtered out:
&lt;start&gt;
aping		9
 the		4
 affecting	3
&lt;end&gt;
&lt;start&gt;
[prompt truncated …]
&lt;end&gt;
[prompt truncated …]

Explanation of neuron 4 behavior: the main thing this neuron does is find
</div></div> </details>
        <div style="text-align: center; margin: auto;">
                <left><p><b>Figure 2:</b> Language models can explain neurons in language models</p></left>
                <center><img class="card-img-top" src="https://github.com/YongceLi/SNIP/blob/main/Method_Step_1.png?raw=true" style="width:400px"></center>
        </div>
    </section>

    <section id="results"/>
        <hr>
        <h2>Experiment Results</h2>
            <div class="flex-row">
                <div class="mx-auto">
                    Working ...
                    <!--
                    <left><p><b>Token Usage Differences:</b>
                    <br>
                    Before the API processes the prompts, the input is broken down into tokens, or parts of words.
                    <br><br>
                    Our proposed prompting methods show significant improvement in token usage over the Original prompt, decreasing API costs and computation time.
                    </p></left>
                    <br>
                    <center><img class="card-img-top" src="assets/token_comparison.jpg" style="width:375px"></center>

                    <br><br>

                    <left><p><b>Simulate and Score: </b>
                    <br>
                    In order to test accuracy of generated explanations, explanations are simulated then scored against the true activations for each excerpt. A simulator model is given the generated explanation along with the text excerpt and asked to predict the activating tokens. The predicted activations are compared to the true activations to calculate accuracy.
                    <br>
                        
                    <br>
                    We evaluate at two sets of neurons in below table, and bolded number is the highest score for each column:  
                    <br>
                    <p style="text-indent: 25px;"> * Random - tested neurons are randomly chosen without a score threshold. 
                    <br>
                    <p style="text-indent: 25px;"> * Random Interpetable - tested neurons are randomly chosen from the pool of neurons with a score higher than 0.35, which is considered reasonably "interpretable". 
                    <br><br>
                    It can be seen that with GPT-3.5 as the explainer model, our <b>Summary</b> prompting method consistently scored highest. With GPT-4 as the explainer model, both the <b>Highlight</b> and <b>Original</b> prompting methods scored high. 
                    </p></left>
                    <br>
                    <center><img class="card-img-top" src="assets/simulatescore.jpg" style="width:825px"></center>

                    <br><br>
                    
                    <left><p><b>Ada + Cosine Similarity:  </b>
                    <br>
                    Another method of testing accuracy of generated explanations is AdaCS. Both the generated explanation and a predetermined "ground truth" explanation for the neuron are converted into text embeddings or word vectors by OpenAI's Ada model. The word vectors are then compared through cosine similarity to determine accuracy.
                    <br><br>
                    In addition to the Random neurons and Random Interpretable neurons defined above, we also evaluate on another two sets of neurons in the below table, where bolded is the highest score for each column: 
                    <br>
                    <p style="text-indent: 25px;"> * Top 20 per layer - top 20 highest scoring neurons from each layer
                    <br>
                    <p style="text-indent: 25px;"> * Top 1k - top 1000 highest scoring neurons from the entire neural network
                    <br><br>
                    It can be seen that on average, the <b>HighlightSummary (HS)</b> prompting method scored highest.
                    </p></left>
                    <center><img class="card-img-top" src="assets/adacs.jpg" style="width:1000px"></center>

                    <br><br>
                    
                    <left><p><b>Human Evaluation: </b>
                    <br>
                    Subjects were given a text excerpt and its highly activating tokens along with 5 generated explanations, one for each prompting method. They were asked to rank each explanation from 1-5 (5 being best) and choose one explanation that they felt best described the text excerpt and its activations.
                    <br><br>
                    We bolded the numbers that is the highest score for each column. It can be seen in the below table that on average, our proposed <b>Summary</b> prompting method scored highest, while <b>HighlightSummary (HS)</b> prompt's explanation had the highest percentage chosen as best.
                    </p></left>
                    <br>
                    <center><img class="card-img-top" src="assets/humanevaluation.jpg" style="width:775px"></center>
                    -->
                </div>
            </div>

    </section>


    <section>
        This webpage template was recycled from <a href='https://nv-tlabs.github.io/LION/'>here</a>.
        <center><p><a href='https://accessibility.ucsd.edu/'><b>Accessibility</b></a></p></center>
    </section>
    


</div>
</body>
</html>
