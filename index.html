<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<script src="bootstrap.js"></script>
<script type="text/javascript" charset="utf-8" src="https://ajax.googleapis.com/ajax/libs/jquery/1.3.2/jquery.min.js"></script> 
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<style type="text/css">
    details > summary {
        display: inline-block;
        border: 2px solid #5C5962;
        border-radius: 5px;
        padding: 5px 10px;
        cursor: pointer;
        color: #0066CD;
        outline: none;
        font-size: 16px;
        background-color: white;
        list-style: none;
    }

    details > summary::-webkit-details-marker {
        display: none;
    }

    /* To remove the additional padding and margin */
    details {
        padding: 0;
        border: none;
    }

    details[open] > summary {
        border-bottom-left-radius: 0;
        border-bottom-right-radius: 0;
    }

    /* Optional: Add some padding and a border to the content for when the details are open */
    details > div {
        border: none;
        border-top: none;
        border-bottom-left-radius: 5px;
        border-bottom-right-radius: 5px;
        padding: 10px;
    }
body {
    font-family: "Titillium Web", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight: 300;
    font-size: 17px;
    margin-left: auto;
    margin-right: auto;
}

@media screen and (min-width: 980px){
    body {
        width: 980px;
    }
}

h1 {
    font-weight:300;
    line-height: 1.15em;
}

h2 {
    font-size: 1.75em;
}
a:link,a:visited {
    color: #5364cc;
    text-decoration: none;
}
a:hover {
    color: #208799;
}
h1 {
    text-align: center;
}
h2,h3 {
    text-align: left;
}

h1 {
    font-size: 40px;
    font-weight: 500;
}
h2 {
    font-weight: 400;
    margin: 16px 0px 4px 0px;
}
h3 {
    font-weight: 600;
    margin: 16px 0px 4px 0px;
}

.paper-title {
    padding: 1px 0px 1px 0px;
}
section {
    margin: 32px 0px 32px 0px;
    text-align: justify;
    clear: both;
}
.col-5 {
     width: 20%;
     float: left;
}
.col-4 {
     width: 25%;
     float: left;
}
.col-3 {
     width: 33%;
     float: left;
}
.col-2 {
     width: 50%;
     float: left;
}
.col-1 {
     width: 100%;
     float: left;
}

.author-row, .affil-row {
    font-size: 26px;
}

.author-row-new { 
    text-align: center; 
}

.author-row-new a {
    display: inline-block;
    font-size: 20px;
    padding: 4px;
}

.author-row-new sup {
    color: #313436;
    font-size: 12px;
}

.affiliations-new {
    font-size: 18px;
    text-align: center;
    width: 80%;
    margin: 0 auto;
    margin-bottom: 20px;
}

.row {
    margin: 16px 0px 16px 0px;
}
.authors {
    font-size: 26px;
}
.affiliatons {
    font-size: 18px;
}
.affil-row {
    margin-top: 18px;
}
.teaser {
    max-width: 100%;
}
.text-center {
    text-align: center;  
}
.screenshot {
    width: 256px;
    border: 1px solid #ddd;
}
.screenshot-el {
    margin-bottom: 16px;
}
hr {
    height: 1px;
    border: 0; 
    border-top: 1px solid #ddd;
    margin: 0;
}
.material-icons {
    vertical-align: -6px;
}
p {
    line-height: 1.25em;
}
.caption {
    font-size: 16px;
    color: #666;
    margin-top: 4px;
    margin-bottom: 10px;
}


video {
    display: block;
    margin: auto;
}


figure {
    display: block;
    margin: auto;
    margin-top: 10px;
    margin-bottom: 10px;
}
#bibtex pre {
    font-size: 14px;
    background-color: #eee;
    padding: 16px;
}
.blue {
    color: #2c82c9;
    font-weight: bold;
}
.orange {
    color: #d35400;
    font-weight: bold;
}
.flex-row {
    display: flex;
    flex-flow: row wrap;
    padding: 0;
    margin: 0;
    list-style: none;
}

.paper-btn-coming-soon {
    position: relative; 
    top: 0;
    left: 0;
}

.coming-soon {
    position: absolute;
    top: -15px;
    right: -15px;
}

.paper-btn {
  position: relative;
  text-align: center;

  display: inline-block;
  margin: 8px;
  padding: 8px 8px;

  border-width: 0;
  outline: none;
  border-radius: 2px;
  
  background-color: #5364cc;
  color: white !important;
  font-size: 20px;
  width: 100px;
  font-weight: 600;
}
.paper-btn-parent {
    display: flex;
    justify-content: center;
    margin: 16px 0px;
}

.paper-btn:hover {
    opacity: 0.85;
}

.example-btn {
  position: relative;
  text-align: center;

  display: inline-block;
  margin: 8px;
  padding: 8px 8px;

  border-width: 0;
  outline: none;
  border-radius: 2px;
  
  background-color: #4cd468;
  color: white !important;
  font-size: 20px;
  width: 220px;
  font-weight: 600;
}
.example-btn-parent {
    display: flex;
    justify-content: center;
    margin: 16px 0px;
}

.example-btn:hover {
    opacity: 0.85;
}

.container {
    margin-left: auto;
    margin-right: auto;
    padding-left: 16px;
    padding-right: 16px;
}

.venue {
    font-size: 23px;
}

.topnav {
    background-color: #EEEEEE;
    overflow: hidden;
}

.topnav div {
    max-width: 1070px;
    margin: 0 auto;
}

.topnav a {
    display: inline-block;
    color: black;
    text-align: center;
    vertical-align: middle;
    padding: 16px 16px;
    text-decoration: none;
    font-size: 18px;
}

.topnav img {
    padding: 2px 0px;
    width: 100%;
    margin: 0.2em 0px 0.3em 0px;
    vertical-align: middle;
}

pre {
    font-size: 0.9em;
    padding-left: 7px;
    padding-right: 7px;
    padding-top: 3px;
    padding-bottom: 3px;
    border-radius: 3px;
    background-color: rgb(235, 235, 235);
    overflow-x: auto;
}

.download-thumb {
    display: flex;
}

@media only screen and (max-width: 620px) {
    .download-thumb {
        display: none;
    }
}

.paper-stuff {
    width: 50%;
    font-size: 20px;
}

@media only screen and (max-width: 620px) {
    .paper-stuff {
        width: 100%;
    }
}
* {
  box-sizing: border-box;
}

.column {
  text-align: center;
  float: left;
  width: 16.666%;
  padding: 5px;
}
.column3 {
  text-align: center;
  float: left;
  width: 33.333%;
  padding: 5px;
}
.column4 {
  text-align: center;
  float: left;
  width: 50%;
  padding: 5px;
}
.column5 {
  text-align: center;
  float: left;
  width: 20%;
  padding: 5px;
}
.border-right {
    border-right: 1px solid black;
}
.border-bottom{
    border-bottom: 1px solid black;
}



/* Clearfix (clear floats) */
.row::after {
  content: "";
  clear: both;
  display: table;
}
.img-fluid {
  max-width: 100%;
  height: auto;
}
.figure-img {
  margin-bottom: 0.5rem;
  line-height: 1;
}








.rounded-circle {
  border-radius: 50% !important;
}






/* Responsive layout - makes the three columns stack on top of each other instead of next to each other */
@media screen and (max-width: 500px) {
  .column {
    width: 100%;
  }
}
@media screen and (max-width: 500px) {
  .column3 {
    width: 100%;
  }
}

</style>
<link rel="stylesheet" href="bootstrap-grid.css">

<script type="text/javascript" src="../js/hidebib.js"></script>
    <link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
    <head>
        <title>SNIP: Machine Unlearning via Selective Neuron-wise Interpretable Pruning</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta property="og:description" content="SNIP: Machine Unlearning via Selective Neuron-wise Interpretable Pruning"/>
        <link href="https://fonts.googleapis.com/css2?family=Material+Icons" rel="stylesheet">
    </head>

 <body>


<div class="container">
    <div class="paper-title">
    <h1> 
        &#9986; SNIP: Machine Unlearning via Selective Neuron-wise Interpretable Pruning
    </div>

    <div id="authors">
        <center>
            <div class="author-row-new">
                Yongce Li,
                Mentor: Tsui-Wei (Lily) Weng
            </div>
        </center>
        <center>
        <div class="affiliations">
            <span> {yol013, lweng} @ucsd.edu </span>
        </div>

        <div class="affil-row">
            <div class="venue text-center"><b>HDSI Capstone 2024</b></div>
        </div>

        </center>

        <div style="clear: both">
            <div class="paper-btn-parent">
            <a class="paper-btn" href="TBA">
                <span class="material-icons"> description </span> 
                 Paper
            </a>
            <div class="paper-btn-coming-soon">
                <a class="paper-btn" href="TBA">
                    <span class="material-icons"> code </span>
                    Code
                </a>
            </div>
        </div></div>
        <!--
        <div style="clear: both">
            <div class="example-btn-parent">
            <a class="example-btn" href="./examples.html">
                <span class="material-icons"> dashboard </span> 
                 Neuron Examples
            </a>
        </div></div>
        -->
    </div>
    

    
    <section id="abstract"/>
        <hr>
        <h2>Abstract</h2>
        <div class="flex-row">
            <p>
                Large Language models (LLMs) have revolutionized the field of natural language processing with their remarkable performance across various applications. However, they suffer from issues related to untruthfulness and toxicity. With evolving data regulations, machine unlearning (MU) is becoming increasingly important to remove undesired outputs of LLMs, such as harmful, manipulated, or outdated information. This paper introduces a machine unlearning method specifically designed for LLMs. We present <b>S</b>elective <b>N</b>euron-wise <b>I</b>nterpretable <b>P</b>runing (<b>SNIP</b>), a machine unlearning method for LLMs, which is retrain-free and interpretable. SNIP selectively remove feed-forward layer neurons based on the relative importance of their neuron explanations on a targeted downstream task. To the best of our knowledge, SNIP is the first <em>interpretable</em> MU approach based on neuron concepts, which helps us understand and remove what have been learned in LLMs.
            </p>
            <div style="text-align: center; margin: auto;">
                <left><p><b>Figure 1:</b> Example of unlearning toxicity.</p></left>
                <center><img class="card-img-top" src="https://github.com/YongceLi/SNIP/blob/main/example_MU.png?raw=true" style="width:400px"></center>
            </div>
        </div>
    </section>

    <section id="motivation"/>
        <hr>
        <h2>Motivation</h2>
        <div class="flex-row">
            <p>
                <b>Interpretability:</b> <a href="https://openai.com/research/language-models-can-explain-neurons-in-language-models">OpenAI’s recent work [1]</a> showed that highly activated MLP neurons in LLMs are correlated with specific concepts, and we can use more capable LLMs (like GPT-4) to extract neuron concepts.<br><br>

                <b>Causal Relationship:</b> <a href="https://gandissect.csail.mit.edu/">Past work [2]</a> showed that by activating and deactivating sets of neurons in a GAN, we can control what objects to appear/disappear in the generated images.<br><br>

                <b>Question:</b> Are MLP neurons in LLMs also causally related with their detected concepts in model’s output? If so, can we control the model’s behavior by controlling the activation value of certain groups of neurons?  

            </p>
        </div>
    </section>

    <section id="method"/>
        <hr>
        <h2>Method</h2>
            <p>In this section, we describe SNIP step by step. In short, SNIP can be decomposed into 4 steps: 
            <ol>
                <li>For a subject model, using approach described in <a href="https://openai.com/research/language-models-can-explain-neurons-in-language-models">[1]</a> to get a concept set for all the MLP neurons, denote as C = {c<sub>ij</sub>}</li>
                <li>Given a forgetting dataset D, prompt GPT-4 to get important concept sets for D, denote as C'</li>
                <li>For each neuron n<sub>ij</sub> (neuron at i<sup>th</sup> MLP layer, j<sup>th</sup> index), calculate importance score s<sub>ij</sub> based on the similarity value between c<sub>ij</sub> and C'</li>
                <li>Rank all the MLP neurons based on their importance score, prune the top k neurons (k is a hyperparameter to be determined).</li>
            </ol>
            </p>
        <h3>Step 1: Interpret MLP neurons and get neuron concept sets C</h3>
            <p>In this step, our goal is to get neuron concept for all the MLP neurons in the subject model. We strictly follow the procedure introduced by OpenAI, using GPT-4 to summarize highly activated tokens of a neuron. Figure 2 shows the whole explanation pipeline. We first probe the subject model with a probing dataset. For each neuron, each token has an unique activation value, while some tokens are highly activated (marked as green). We prompt GPT-4 to summarize those tokens thus describe the functionality of that neuron. 
            </p>
            <details> 
                <summary>GPT-4 prompt to get C</summary> 
                <br> <div style="white-space: pre-wrap;">
We're studying neurons in a neural network. Each neuron looks for some particular thing in a short document. Look at the parts of the document the neuron activates for and summarize in a single sentence what the neuron is looking for. Don't list examples of words.

The activation format is token&lt;tab&gt;activation. Activation values range from 0 to 10. A neuron finding what it's looking for is represented by a non-zero activation value. The higher the activation value, the stronger the match.

Neuron 1
Activations:
&lt;start&gt;
the		0
 sense		0
 of		0
 together	3
ness		7
 in		0
 our		0
 town		1
 is		0
 strong		0
.		0
&lt;end&gt;
&lt;start&gt;
[prompt truncated …]
&lt;end&gt;

Same activations, but with all zeros filtered out:
&lt;start&gt;
 together	3
ness		7
town		1
&lt;end&gt;
&lt;start&gt;
[prompt truncated …]
&lt;end&gt;

Explanation of neuron 1 behavior: the main thing this neuron does is find phrases related to community

[prompt truncated …]

Neuron 4
Activations:
&lt;start&gt;
Esc		0
aping		9
 the		4
 studio		0
,		0
 Pic		0
col		0
i		0
 is		0
 warmly	0
 affecting	3
&lt;end&gt;
&lt;start&gt;
[prompt truncated …]
&lt;end&gt;

Same activations, but with all zeros filtered out:
&lt;start&gt;
aping		9
 the		4
 affecting	3
&lt;end&gt;
&lt;start&gt;
[prompt truncated …]
&lt;end&gt;
[prompt truncated …]

Explanation of neuron 4 behavior: the main thing this neuron does is find
</div> </details>
        <div style="text-align: center; margin: auto;">
                <left><p><b>Figure 2:</b> Language models can explain neurons in language models</p></left>
                <center><img class="card-img-top" src="https://github.com/YongceLi/SNIP/blob/main/Method_Step_1.png?raw=true" style="width:445px"></center>
        </div>
        <h3>Step 2: Get concept set C' for forgetting dateset D</h3>
        <p>In this step, we aim to use large language model to capture important concepts embedded in a given dataset. Once we get the dataset concept sets, we will be able to compare neuron concepts with dataset concepts, thus computing an importance score for each neuron to the given dataset. We detailedly instruct the model with examples of neuron concepts to ensure the output is in high quality.</p>
        <details> 
                <summary>GPT-4 prompt to get C'</summary> 
                <br> <div style="white-space: pre-wrap;">We're studying how neurons in a neural network affect the model's performance on specific tasks. Each neuron looks for some particular thing in a short document. To measure how neurons are related to the given task, we want to know what concepts are important for the task. 

Neuron concepts examples:
1. the past and present tense of the verb "to be" (was, were, is).
2. variations of the verb 'be'.
3. modal verbs, especially "would" and "were".
4. action verbs related to starting or beginning.
5. future tense verbs and words related to commitment.
6. the usage of the verb "to be" and its conjugations.
7. the verb 'use' and its variations.
8. the word "could" and similar auxiliary verbs indicating possibility.
9. the word "like" and its variations, as well as other verbs expressing desire or interest.
10. verbs related to posting and sharing information.

Given the input samples below:

sample1: ...
sample2: ...

List a comprehensive list of categories of concepts that are important for language models to comprehend the given texts. Output in the following format:
1. concept1
2. concept2
...
                </div></details>
        <div style="text-align: center; margin: auto;">
                <left><p><b>Figure 3:</b> Language models can extract important concept in a dataset</p></left>
                <center><img class="card-img-top" src="https://github.com/YongceLi/SNIP/blob/main/Method_Step_2.png?raw=true" style="width:500px"></center>
        </div>
        <h3>Step 3: Get importance score for each neuron</h3>
        <p>Since we got neuron concept c<sub>ij</sub> for each neuron n<sub>ij</sub> and dataset concept sets C' for D, we want to find a systematic way to compare them. As they are all represented by sentences, an efficient method is to embed them into vectors and use cosine similarity to encode their distance. We use the maximum similarity value between neuron concept and each dataset concept to represent the importance of a neuron to the given forgetting dataset.</p>
        <div style="text-align: center; margin: auto;">
                <left><p><b>Figure 4:</b> Embedding extracted concepts into vectors</p></left>
                <center><img class="card-img-top" src="https://github.com/YongceLi/SNIP/blob/main/Method_Step_3.png?raw=true" style="width:500px"></center>
        </div>
        <h3>Step 4: Prune neurons based on importance score</h3>
        <p>Our goal is to let the model forget concepts they learned in the forgetting dataset D. While we have each neuron's importance score to D, intuitively, we rank all the neurons based on their importance score from high to low, and prune the top k neurons. (k is a hyperparameter users can adjust to trade off between the effectiveness of forgetting and the overall capabilities of the subject model)</p>
    </section>

    <section id="results"/>
        <hr>
        <h2>Experiment Results</h2>
            <div class="flex-row">
                <div class="mx-auto">
                    <p>We tested our method on two different tasks, text comprehension and toxicity reduction, on GPT-2 model. To have a more comprehensive evaluation of our method, we compared SNIP with 3 prune-based unlearning baseline methods. 
                        <ul>
                        <li><b>Prune random neurons:</b> Randomly prune k MLP neurons</li>
                        <li><b>Prune based on concept keyword:</b> Manually choose a keyword set K = {keyword<sub>i</sub>} for the forgetting dataset D. Select n<sub>ij</sub> if and only if there exists i such that keyword<sub>i</sub> &isin; c<sub>ij</sub>. Prune the top k neurons based on their concept explanation score in step 1.</li>
                        <li><b>Prune GPT-4 selected neurons:</b> We prompt GPT-4 with dataset examples and neuron concepts, and let it assign an importance score ranged from 0 to 10 to each neuron. Prune the top k high score neurons.</li>
                        </ul></p>
                    <h3>GPT-2: Unlearning Children's Book Test dataset</h3>
                    <p>The Children’s Book Test (CBT) was
created to examine the performance of LMs on different categories of words: named entities, nouns, verbs, and prepositions. CBT reports accuracy on an automatically constructed cloze test where the task is to predict which of 10 possible
choices for an omitted word is correct. In our experiment, our forgetting dataset D consists of 100 randomly selected samples from CBT training set, and we choose OpenAI's <a href="https://platform.openai.com/docs/guides/embeddings">text-embedding-3-small</a> model as our embedding model in step 3.</p>
                    <details> 
                        <summary>Example of CBT dataset</summary> 
                        <br> <div style="white-space: pre-wrap;"><b>Context:</b><br>With almost everything else to make them happy , they wanted one thing : they had no children .This vexed the king even more than the queen , who was very clever and learned , and who had hated dolls when she was a child . However , she , too in spite of all the books she read and all the pictures she painted , would have been glad enough to be the mother of a little prince . The king was anxious to consult the fairies , but the queen would not hear of such a thing . She did not believe in fairies : she said that they had never existed ; and that she maintained , though The History of the Royal Family was full of chapters about nothing else . Well , at long and at last they had a little boy , who was generally regarded as the finest baby that had ever been seen . Even her majesty herself remarked that , though she could never believe all the courtiers told her , yet he certainly was a fine child -- a very fine child . Now , the time drew near for the christening party , and the king and queen were sitting at breakfast in their summer parlour talking over it . It was a splendid room , hung with portraits of the royal ancestors . There was Cinderella , the grandmother of the reigning monarch , with her little foot in her glass slipper thrust out before her . There was the Marquis de Carabas , who , as everyone knows , was raised to the throne as prince consort after his marriage with the daughter of the king of the period . On the arm of the throne was seated his celebrated cat , wearing boots . There , too , was a portrait of a beautiful lady , sound asleep : this was Madame La Belle au Bois-dormant , also an ancestress of the royal family . Many other pictures of celebrated persons were hanging on the walls . `` You have asked all the right people , my dear ? '' said the king . `` Everyone who should be asked , '' answered the queen . `` People are so touchy on these occasions , '' said his majesty . `` You have not forgotten any of our aunts ? '' `` No ; the old cats ! ''<br><b>Next sentence:</b><br>replied the XXXXX ; for the king 's aunts were old-fashioned , and did not approve of her , and she knew it .<br><b>Choices:</b><br>["ancestors", "baby", "boy", "everyone", "fairies", "mother", "portrait", "queen", "time", "walls"]<br><b>Correct answer:</b><br>queen
                    </details>
                </div>
            </div>

    </section>


    <section>
        This webpage template was recycled from <a href='https://nv-tlabs.github.io/LION/'>here</a>.
        <center><p><a href='https://accessibility.ucsd.edu/'><b>Accessibility</b></a></p></center>
    </section>
    


</div>
</body>
</html>
